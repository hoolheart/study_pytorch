{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries before diving\n",
    "\n",
    "- basic mathmatics tools and functions\n",
    "- basic data process\n",
    "- basic probability theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import PyTorch V1.12.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.distributions import multinomial\n",
    "from d2l import torch as d2l\n",
    "print(f'Import PyTorch V{torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of tensors\n",
    "\n",
    "Major creations:\n",
    "\n",
    "1. arange: generate an ascending sequence\n",
    "1. zeros: generate a tensor whose elements are initialized as 0\n",
    "1. ones: generate a tensor whose elements are initialized as 1\n",
    "1. rand: generate a tensor whose elements folow uniform distribution in [0, 1]\n",
    "1. randn: generate a tensor whose elements follow N(0, 1)\n",
    "1. tensor: convert a numerical array into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a tensor: tensor([0., 1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
      "Its shape is torch.Size([8]), and it contains 8 elements\n"
     ]
    }
   ],
   "source": [
    "t0 = torch.arange(8, dtype=torch.float64)\n",
    "print(f'Create a tensor: {t0}')\n",
    "print(f'Its shape is {t0.shape}, and it contains {t0.numel()} elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape tensor to a matrix with two rows:\n",
      "tensor([[0., 1., 2., 3.],\n",
      "        [4., 5., 6., 7.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(f'Reshape tensor to a matrix with two rows:\\n{t0.reshape(2, -1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create tensor with shape (2, 3, 2) by several common creations\n",
      "\n",
      "zeros\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "ones\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]])\n",
      "rand\n",
      "tensor([[[0.3903, 0.3388],\n",
      "         [0.8930, 0.0400],\n",
      "         [0.3242, 0.3888]],\n",
      "\n",
      "        [[0.0192, 0.7735],\n",
      "         [0.5768, 0.9349],\n",
      "         [0.9278, 0.6997]]])\n",
      "randn\n",
      "tensor([[[ 0.3485,  1.0988],\n",
      "         [-0.4499, -0.4190],\n",
      "         [-0.1093, -0.3022]],\n",
      "\n",
      "        [[ 1.1509,  0.9226],\n",
      "         [-1.0440,  0.3633],\n",
      "         [ 1.4196,  0.2340]]])\n"
     ]
    }
   ],
   "source": [
    "creations = [torch.zeros, torch.ones, torch.rand, torch.randn]\n",
    "shape = (2, 3, 2)\n",
    "print(f'Create tensor with shape {shape} by several common creations')\n",
    "print()\n",
    "for func in creations:\n",
    "    print(func.__name__)\n",
    "    print(func(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an integer tensor from an array:\n",
      "tensor([[2, 1, 3],\n",
      "        [1, 2, 1]])\n",
      "Shape: torch.Size([2, 3])\n",
      "DType: torch.int64\n",
      "Size: 6\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([[2, 1, 3], [1, 2, 1]])\n",
    "print(f'Create an integer tensor from an array:\\n{t2}')\n",
    "print(f'Shape: {t2.shape}')\n",
    "print(f'DType: {t2.dtype}')\n",
    "print(f'Size: {t2.numel()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 CUDA devices\n",
      "Try create a tensor in GPU\n",
      "tensor([0.3648, 0.4555, 0.5713, 0.9631, 0.8859, 0.0505, 0.1546, 0.4615],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {torch.cuda.device_count()} CUDA devices')\n",
    "if torch.cuda.is_available():\n",
    "    print('Try create a tensor in GPU')\n",
    "    t3 = torch.rand_like(t0, dtype=torch.float32, device=torch.device(type='cuda'))\n",
    "    print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from csv files\n",
    "\n",
    "Use pandas to load data and convert into tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare csv data file\n"
     ]
    }
   ],
   "source": [
    "print('Prepare csv data file')\n",
    "os.makedirs('data', exist_ok=True)\n",
    "data_file = os.path.join('data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('room_count, alley, price\\n')\n",
    "    f.write('NA, Pave, 127500\\n')\n",
    "    f.write('2, NA, 106000\\n')\n",
    "    f.write('4, NA, 178100\\n') \n",
    "    f.write('NA, NA, 140000\\n')\n",
    "    f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data by using Pandas V1.4.3\n",
      "   room_count alley   price\n",
      "0         NaN  Pave  127500\n",
      "1         2.0   NaN  106000\n",
      "2         4.0   NaN  178100\n",
      "3         NaN   NaN  140000\n"
     ]
    }
   ],
   "source": [
    "print(f'Load data by using Pandas V{pd.__version__}')\n",
    "houses = pd.read_csv(data_file, skipinitialspace=True)\n",
    "print(houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider price as function of room count and alley\n",
      "inputs: \n",
      "   room_count alley\n",
      "0         NaN  Pave\n",
      "1         2.0   NaN\n",
      "2         4.0   NaN\n",
      "3         NaN   NaN\n",
      "outputs: \n",
      "0    127500\n",
      "1    106000\n",
      "2    178100\n",
      "3    140000\n",
      "Name: price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Consider price as function of room count and alley')\n",
    "inputs, outputs = houses.loc[:, ('room_count', 'alley')], houses.loc[:, 'price']\n",
    "print(f'inputs: \\n{inputs}')\n",
    "print(f'outputs: \\n{outputs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill inputs by using mean values\n",
      "   room_count alley\n",
      "0         3.0  Pave\n",
      "1         2.0   NaN\n",
      "2         4.0   NaN\n",
      "3         3.0   NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prett\\AppData\\Local\\Temp\\ipykernel_26196\\3806031187.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  inputs = inputs.fillna(inputs.mean())\n"
     ]
    }
   ],
   "source": [
    "print('Fill inputs by using mean values')\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use integers to represent category-like attributes\n",
      "   room_count  alley_Pave  alley_nan\n",
      "0         3.0           1          0\n",
      "1         2.0           0          1\n",
      "2         4.0           0          1\n",
      "3         3.0           0          1\n"
     ]
    }
   ],
   "source": [
    "print('Use integers to represent category-like attributes')\n",
    "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert Pandas DataFrame into PyTorch tensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 1., 0.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 0., 1.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500, 106000, 178100, 140000]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Convert Pandas DataFrame into PyTorch tensor')\n",
    "inputs, outputs = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
    "inputs, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(42.), tensor(0.7000))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('prepare scalars')\n",
    "s0 = torch.tensor(42.0)\n",
    "s1 = torch.tensor(0.7)\n",
    "s0, s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5]), tensor([1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('prepare vectors')\n",
    "v0 = torch.arange(6)\n",
    "v1 = torch.ones((6))\n",
    "v0, v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare matrices\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]]),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('prepare matrices')\n",
    "m0 = torch.arange(12).reshape((3, 4))\n",
    "m1 = torch.ones((3, 4))\n",
    "m0, m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare tensors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2],\n",
       "          [ 3,  4,  5],\n",
       "          [ 6,  7,  8]],\n",
       " \n",
       "         [[ 9, 10, 11],\n",
       "          [12, 13, 14],\n",
       "          [15, 16, 17]]]),\n",
       " tensor([[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('prepare tensors')\n",
    "t0 = torch.arange(18).reshape((2, 3, 3))\n",
    "t1 = torch.ones((2, 3, 3))\n",
    "t0, t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = [s0, s1, v0, v1, m0, m1, t0, t1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: torch.float32, shape: torch.Size([])\n",
      "dtype: torch.float32, shape: torch.Size([])\n",
      "dtype: torch.int64, shape: torch.Size([6])\n",
      "dtype: torch.float32, shape: torch.Size([6])\n",
      "dtype: torch.int64, shape: torch.Size([3, 4])\n",
      "dtype: torch.float32, shape: torch.Size([3, 4])\n",
      "dtype: torch.int64, shape: torch.Size([2, 3, 3])\n",
      "dtype: torch.float32, shape: torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "for t in tensors:\n",
    "    print(f'dtype: {t.dtype}, shape: {t.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape torch.Size([]), sum of axis None: tensor(42.)\n",
      "Shape torch.Size([6]), sum of axis None: tensor(15)\n",
      "Shape torch.Size([6]), sum of axis 0: tensor(6.)\n",
      "Shape torch.Size([3, 4]), sum of axis None: tensor(66)\n",
      "Shape torch.Size([3, 4]), sum of axis 1: tensor([ 6, 22, 38])\n",
      "Shape torch.Size([2, 3, 3]), sum of axis 2: tensor([[ 3, 12, 21],\n",
      "        [30, 39, 48]])\n",
      "Shape torch.Size([2, 3, 3]), sum of axis 0: tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "for t, axis in [\n",
    "    (s0, None), (v0, None), (v1, 0), (m0, None), (m0, 1), (t0, 2), (t1, 0)\n",
    "]:\n",
    "    print(f'Shape {t.shape}, sum of axis {axis}: ', end='')\n",
    "    if axis is None:\n",
    "        print(t.sum())\n",
    "    else:\n",
    "        print(t.sum(axis=axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]]),\n",
       " tensor([12, 15, 18, 21]),\n",
       " tensor([ 6, 22, 38]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m0, m0.sum(axis=0), m0.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.5000),\n",
       " 12,\n",
       " tensor([4., 5., 6., 7.]),\n",
       " tensor([[1.5000],\n",
       "         [5.5000],\n",
       "         [9.5000]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m0_float = m0.to(torch.float32)\n",
    "m0_float.mean(), m0_float.numel(), m0_float.mean(axis=0), m0_float.mean(axis=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(15.),\n",
       " tensor([6., 6.]),\n",
       " tensor([[ 6.,  6.,  6.],\n",
       "         [22., 22., 22.],\n",
       "         [38., 38., 38.]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(v0.to(dtype=torch.float32), v1), torch.mv(m1.reshape((2, 6)), v1), torch.mm(m0.to(dtype=torch.float32), m1.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([]), tensor(42.))\n",
      "(torch.Size([]), tensor(0.7000))\n",
      "(torch.Size([6]), tensor(7.4162))\n",
      "(torch.Size([6]), tensor(2.4495))\n",
      "(torch.Size([3, 4]), tensor(22.4944))\n",
      "(torch.Size([3, 4]), tensor(3.4641))\n",
      "(torch.Size([2, 3, 3]), tensor(42.2493))\n",
      "(torch.Size([2, 3, 3]), tensor(4.2426))\n"
     ]
    }
   ],
   "source": [
    "for t in tensors:\n",
    "    if t.dtype == torch.int64:\n",
    "        t = t.to(dtype=torch.float32)\n",
    "    print((t.shape, t.norm()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto computing of differentiation\n",
    "\n",
    "- First, create gradient of independent variables. There are two ways:\n",
    "    - call tensor variable's `requires_grad_(True)` method;\n",
    "    - add `requires_grad=True` argument when creating the variable.\n",
    "- Then, generate dependent scalar variable.\n",
    "- Call dependent scalar variable's `backward()` function to update independent variable's `grad` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " tensor([0., 1., 2., 3., 4., 5.], requires_grad=True))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.requires_grad_(True)\n",
    "v2 = torch.arange(6.0, requires_grad=True)\n",
    "\n",
    "v1, v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15., grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.dot(v1, v2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.grad, v2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3., 4., 5.]), tensor([1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "v1.grad, v2.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two special methods:\n",
    "\n",
    "- `zero_()` on `grad` attribute to clear previous gradient\n",
    "- `detach()` on independent variable to generate a new variable without gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6., grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.grad.zero_()\n",
    "tmp = v1.detach()\n",
    "y2 = torch.dot(tmp, v1)\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.grad, v1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2.backward()\n",
    "tmp.grad, v1.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-normial Distribution\n",
    "\n",
    "Multinormial distribution is one of PyTorch supported distribution models.\n",
    "The usage of one distribution model contains two aspects en general:\n",
    "\n",
    "1. creation of distribution variable\n",
    "1. sampling of distribution variable via `sample` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Multinomial in module torch.distributions.multinomial:\n",
      "\n",
      "class Multinomial(torch.distributions.distribution.Distribution)\n",
      " |  Multinomial(total_count=1, probs=None, logits=None, validate_args=None)\n",
      " |  \n",
      " |  Creates a Multinomial distribution parameterized by :attr:`total_count` and\n",
      " |  either :attr:`probs` or :attr:`logits` (but not both). The innermost dimension of\n",
      " |  :attr:`probs` indexes over categories. All other dimensions index over batches.\n",
      " |  \n",
      " |  Note that :attr:`total_count` need not be specified if only :meth:`log_prob` is\n",
      " |  called (see example below)\n",
      " |  \n",
      " |  .. note:: The `probs` argument must be non-negative, finite and have a non-zero sum,\n",
      " |            and it will be normalized to sum to 1 along the last dimension. :attr:`probs`\n",
      " |            will return this normalized value.\n",
      " |            The `logits` argument will be interpreted as unnormalized log probabilities\n",
      " |            and can therefore be any real number. It will likewise be normalized so that\n",
      " |            the resulting probabilities sum to 1 along the last dimension. :attr:`logits`\n",
      " |            will return this normalized value.\n",
      " |  \n",
      " |  -   :meth:`sample` requires a single shared `total_count` for all\n",
      " |      parameters and samples.\n",
      " |  -   :meth:`log_prob` allows different `total_count` for each parameter and\n",
      " |      sample.\n",
      " |  \n",
      " |  Example::\n",
      " |  \n",
      " |      >>> m = Multinomial(100, torch.tensor([ 1., 1., 1., 1.]))\n",
      " |      >>> x = m.sample()  # equal probability of 0, 1, 2, 3\n",
      " |      tensor([ 21.,  24.,  30.,  25.])\n",
      " |  \n",
      " |      >>> Multinomial(probs=torch.tensor([1., 1., 1., 1.])).log_prob(x)\n",
      " |      tensor([-4.1338])\n",
      " |  \n",
      " |  Args:\n",
      " |      total_count (int): number of trials\n",
      " |      probs (Tensor): event probabilities\n",
      " |      logits (Tensor): event log probabilities (unnormalized)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Multinomial\n",
      " |      torch.distributions.distribution.Distribution\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, total_count=1, probs=None, logits=None, validate_args=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  entropy(self)\n",
      " |      Returns entropy of distribution, batched over batch_shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tensor of shape batch_shape.\n",
      " |  \n",
      " |  expand(self, batch_shape, _instance=None)\n",
      " |      Returns a new distribution instance (or populates an existing instance\n",
      " |      provided by a derived class) with batch dimensions expanded to\n",
      " |      `batch_shape`. This method calls :class:`~torch.Tensor.expand` on\n",
      " |      the distribution's parameters. As such, this does not allocate new\n",
      " |      memory for the expanded distribution instance. Additionally,\n",
      " |      this does not repeat any args checking or parameter broadcasting in\n",
      " |      `__init__.py`, when an instance is first created.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch_shape (torch.Size): the desired expanded size.\n",
      " |          _instance: new instance provided by subclasses that\n",
      " |              need to override `.expand`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          New distribution instance with batch dimensions expanded to\n",
      " |          `batch_size`.\n",
      " |  \n",
      " |  log_prob(self, value)\n",
      " |      Returns the log of the probability density/mass function evaluated at\n",
      " |      `value`.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (Tensor):\n",
      " |  \n",
      " |  sample(self, sample_shape=torch.Size([]))\n",
      " |      Generates a sample_shape shaped sample or sample_shape shaped batch of\n",
      " |      samples if the distribution parameters are batched.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  logits\n",
      " |  \n",
      " |  mean\n",
      " |      Returns the mean of the distribution.\n",
      " |  \n",
      " |  param_shape\n",
      " |  \n",
      " |  probs\n",
      " |  \n",
      " |  support\n",
      " |      Returns a :class:`~torch.distributions.constraints.Constraint` object\n",
      " |      representing this distribution's support.\n",
      " |  \n",
      " |  variance\n",
      " |      Returns the variance of the distribution.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'total_count': <class 'int'>}\n",
      " |  \n",
      " |  arg_constraints = {'logits': IndependentConstraint(Real(), 1), 'probs'...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  cdf(self, value)\n",
      " |      Returns the cumulative density/mass function evaluated at\n",
      " |      `value`.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (Tensor):\n",
      " |  \n",
      " |  enumerate_support(self, expand=True)\n",
      " |      Returns tensor containing all values supported by a discrete\n",
      " |      distribution. The result will enumerate over dimension 0, so the shape\n",
      " |      of the result will be `(cardinality,) + batch_shape + event_shape`\n",
      " |      (where `event_shape = ()` for univariate distributions).\n",
      " |      \n",
      " |      Note that this enumerates over all batched tensors in lock-step\n",
      " |      `[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\n",
      " |      along dim 0, but with the remaining batch dimensions being\n",
      " |      singleton dimensions, `[[0], [1], ..`.\n",
      " |      \n",
      " |      To iterate over the full Cartesian product use\n",
      " |      `itertools.product(m.enumerate_support())`.\n",
      " |      \n",
      " |      Args:\n",
      " |          expand (bool): whether to expand the support over the\n",
      " |              batch dims to match the distribution's `batch_shape`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tensor iterating over dimension 0.\n",
      " |  \n",
      " |  icdf(self, value)\n",
      " |      Returns the inverse cumulative density/mass function evaluated at\n",
      " |      `value`.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (Tensor):\n",
      " |  \n",
      " |  perplexity(self)\n",
      " |      Returns perplexity of distribution, batched over batch_shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tensor of shape batch_shape.\n",
      " |  \n",
      " |  rsample(self, sample_shape=torch.Size([]))\n",
      " |      Generates a sample_shape shaped reparameterized sample or sample_shape\n",
      " |      shaped batch of reparameterized samples if the distribution parameters\n",
      " |      are batched.\n",
      " |  \n",
      " |  sample_n(self, n)\n",
      " |      Generates n samples or n batches of samples if the distribution\n",
      " |      parameters are batched.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  set_default_validate_args(value)\n",
      " |      Sets whether validation is enabled or disabled.\n",
      " |      \n",
      " |      The default behavior mimics Python's ``assert`` statement: validation\n",
      " |      is on by default, but is disabled if Python is run in optimized mode\n",
      " |      (via ``python -O``). Validation may be expensive, so you may want to\n",
      " |      disable it once a model is working.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (bool): Whether to enable validation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  batch_shape\n",
      " |      Returns the shape over which parameters are batched.\n",
      " |  \n",
      " |  event_shape\n",
      " |      Returns the shape of a single sample (without batching).\n",
      " |  \n",
      " |  mode\n",
      " |      Returns the mode of the distribution.\n",
      " |  \n",
      " |  stddev\n",
      " |      Returns the standard deviation of the distribution.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  has_enumerate_support = False\n",
      " |  \n",
      " |  has_rsample = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(multinomial.Multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Multinomial()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.tensor([0.1, 0.3, 0.5, 0.1])\n",
    "dist_var = multinomial.Multinomial(probs=probs)\n",
    "dist_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 4]), tensor([103., 302., 498.,  97.]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = dist_var.sample((1000,))\n",
    "samples.shape, samples.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1030, 0.3020, 0.4980, 0.0970]),\n",
       " tensor([0.0030, 0.0020, 0.0020, 0.0030]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rst_probs = samples.sum(dim=0) / samples.shape[0]\n",
    "rst_probs, np.abs(rst_probs - probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ac650165262f90a220c0d6f11cc32e6d2cfff423984774d41fc36868d505633"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
